# Model 2: TF-IDF + Random Forest
## Preprocess
jieba Chinese Tokenizer
## Best Model
```
n_estimators = 500 max_depth = 80 min_samples_leaf = 3 max_features = 0.1
training accuracy = 0.8117558276035552
testing accuracy = 0.6505700871898055
```
## Result
```
      precision    recall  f1-score   support

           0       0.86      0.73      0.79       438
           1       0.94      0.65      0.77       114
           2       1.00      0.43      0.60        49
           3       0.88      0.87      0.88      2739
           4       1.00      0.10      0.18        10
           5       1.00      0.17      0.29        41
           6       0.98      0.67      0.79        78
           7       1.00      0.12      0.22        74
           8       0.94      0.63      0.76       771
           9       0.97      0.42      0.59       285
          10       0.88      0.90      0.89       674
          11       0.63      0.89      0.74      1403
          12       0.88      0.26      0.40       522
          13       0.92      0.62      0.74       336
          14       0.80      0.95      0.86      3322
          15       0.81      0.82      0.82       969
          16       0.94      0.61      0.74       101

    accuracy                           0.81     11926
   macro avg       0.91      0.58      0.65     11926
weighted avg       0.83      0.81      0.80     11926

              precision    recall  f1-score   support

           0       0.52      0.42      0.46       109
           1       0.78      0.26      0.39        27
           2       0.00      0.00      0.00        11
           3       0.75      0.68      0.71       720
           4       0.00      0.00      0.00         4
           5       0.00      0.00      0.00         9
           6       1.00      0.08      0.14        26
           7       0.00      0.00      0.00        12
           8       0.72      0.28      0.40       183
           9       0.62      0.09      0.16        56
          10       0.73      0.81      0.77       155
          11       0.55      0.78      0.64       369
          12       0.74      0.12      0.21       115
          13       0.64      0.26      0.37        95
          14       0.64      0.88      0.74       830
          15       0.62      0.66      0.64       243
          16       0.38      0.17      0.23        18

    accuracy                           0.65      2982
   macro avg       0.51      0.32      0.35      2982
weighted avg       0.66      0.65      0.62      2982
```